{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Sai Anish Garapati\n",
    "# UIN: 650208577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficImageDatset(Dataset):\n",
    "\tdef __init__(self, csv_file, root_dir, transform=None):\n",
    "\t\tself.csv_content = pd.read_csv(csv_file, usecols=['ClassId', 'Path'])\n",
    "\t\tself.root_dir = root_dir\n",
    "\t\tself.transform = transform\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.csv_content)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\timg = Image.open(self.root_dir + self.csv_content.iloc[index, 1])\n",
    "\t\tlabel = torch.tensor(int(self.csv_content.iloc[index, 0]))\n",
    "\n",
    "\t\tif self.transform:\n",
    "\t\t\timg_tensor = self.transform(img)\n",
    "\n",
    "\t\treturn (img_tensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(2304, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(device, model, test_loader):\n",
    "    model.eval()\n",
    "    corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, label) in enumerate(test_loader):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = model(data)\n",
    "            predictions = output.argmax(dim=1, keepdim=True)\n",
    "            corrects += predictions.eq(label.view_as(predictions)).sum().item()\n",
    "\n",
    "        print('Correct: {}, Total: {}, Test Accuracy: {}'.format(corrects, len(test_loader), 100.0 * corrects / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 12128, Total: 12630, Test Accuracy: 96.02533650039588\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2021)\n",
    "\n",
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load('./ML_Model.pt'))\n",
    "\n",
    "root_path = '../../../../ML_Project_Data/'\n",
    "test_batch_size=1\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "test_dataset = TrafficImageDatset(\n",
    "    csv_file=root_path + 'Test.csv', root_dir=root_path, transform=transform)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "test_model(device, loaded_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
